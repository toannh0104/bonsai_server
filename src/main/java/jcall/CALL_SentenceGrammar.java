/**
 * Created on 2007/06/29
 * @author wang
 * Copyrights @kawahara lab
 */
package jcall;

import java.io.BufferedWriter;
import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.util.HashSet;
import java.util.StringTokenizer;
import java.util.Vector;

import jcall.config.FindConfig;
import jcall.recognition.database.DataManager;
import jcall.recognition.dataprocess.EPLeaf;
import jcall.recognition.dataprocess.GrammarWord;
import jcall.recognition.dataprocess.Lexicon;
import jcall.recognition.dataprocess.LexiconProcess;
import jcall.recognition.dataprocess.LexiconWordMeta;
import jcall.recognition.dataprocess.NewLogParser;
import jcall.recognition.dataprocess.PredictionProcess;
import jcall.recognition.dataprocess.SentenceDataMeta;
import jcall.recognition.languagemodel.JulianGram;
import jcall.recognition.languagemodel.MakeDFA;
import jcall.recognition.util.CharacterUtil;

import org.apache.log4j.Logger;

public class CALL_SentenceGrammar {
  static Logger logger = Logger.getLogger(CALL_SentenceGrammar.class.getName());

  static Vector<GrammarWord> network;
  GrammarWord gw;
  GrammarWord pregw = null;
  public static String JGRAMBASE = FindConfig.getConfig().findStr("JGRAMBASE");
  public static final String STR_TAB = new String("\t");
  // public static final String PATH = "D:\\julian";
  public static final String CONTEXTFILENAME = new String("currentQuestion");

  public static String[] particle = { "は", "が", "も", "の", "と", "から", "へ", "に", "を", "で", "まで" };
  DataManager dm;
  LexiconProcess lp;
  PredictionProcess pp;

  public CALL_SentenceGrammar() {
    init();
  }

  private void init() {
    gw = new GrammarWord();
    network = new Vector<GrammarWord>();
    dm = new DataManager();
    try {
      System.out.println("start new PredictionProcess()");
      pp = new PredictionProcess();
    } catch (IOException e1) {
      // TODO Auto-generated catch block
      e1.printStackTrace();
    }
    try {
      lp = new LexiconProcess();
    } catch (IOException e) {
      // TODO Auto-generated catch block
      e.printStackTrace();
    }

  }

  public void oneSentenceGrammar(CALL_sentenceStruct sentence, int lessonNum) {

    LexiconProcess lp = null;
    PredictionProcess pp = null;
    try {
      pp = new PredictionProcess();
    } catch (IOException e1) {
      e1.printStackTrace();
    }
    try {
      lp = new LexiconProcess();
    } catch (IOException e) {
      // TODO Auto-generated catch block
      e.printStackTrace();
    }
    boolean booNegative = false;
    boolean tense = false;
    boolean politeness = false;
    boolean question = false;
    Vector wordList;
    String sentenceStr;
    CALL_sentenceWordStruct tempSentenceWord;

    // print all sentences
    // ===================
    Vector sentenceList = sentence.getAllSentenceStrings(CALL_io.kanji, false);
    if (sentenceList != null) {
      for (int j = 0; j < sentenceList.size(); j++) {
        sentenceStr = (String) sentenceList.elementAt(j);
        if (sentenceStr != null) {
          logger.debug("In all sentences generated by original system, Sentence[" + j + "]: " + sentenceStr);
        }
      }
    }

    // print the top sentence
    sentenceStr = sentence.getSentenceString(CALL_io.kanji);
    // it is the top sentence, using same function with the hintsStruct

    wordList = sentence.getSentenceWords();
    if (wordList != null) {
      network = new Vector<GrammarWord>();
      logger.info("target sentence is " + sentenceStr + " word size is: " + wordList.size());
      for (int i = 0; i < wordList.size(); i++) {
        tempSentenceWord = (CALL_sentenceWordStruct) wordList.elementAt(i);
        gw = new GrammarWord();
        if (tempSentenceWord != null) {
          // tempSentenceWord.print_debug();
          if (tempSentenceWord.word != null) {

            String word = tempSentenceWord.word.kanji;
            logger.info("word " + i + " is " + word);
            gw.toEPWord(tempSentenceWord.word);

            // set id
            logger.info("gw.getIntType(): " + gw.getIntType() + " kanji: " + gw.getStrKanji() + " StrEngKana: "
                + gw.getStrEngKana());

            LexiconWordMeta lwm = lp.getWord(gw.getIntType(), gw.getStrKanji(), gw.getStrEngKana());
            if (lwm == null) {
              lwm = lp.getWord(gw.getStrKanji(), gw.getStrKana(), gw.getStrEngKana());
            }
            if (lwm != null) {
              logger.debug("find target word: [" + word + "]");
              gw.setId(lwm.getId());
              // handle altKana
              String altKana = lwm.getStrAltkana();
              if (altKana != null && altKana.length() > 0) {
                int intKanaType = CharacterUtil.checkWordClass(altKana);
                if (intKanaType == CharacterUtil.TYPE_KATAKANA) {// katakana
                  gw.setStrEngKana(lwm.getStrAltkana());
                } else if (intKanaType == CharacterUtil.TYPE_HIRAGANA) {
                  gw.setStrAltKana(lwm.getStrAltkana());
                } else {
                  logger.error("altKana Type is not katakana or hiragana, but is  " + intKanaType);
                }
              }

              String strGrammarRule = tempSentenceWord.grammarRule;
              String strComponentName = tempSentenceWord.componentName;
              if (strComponentName != null && strComponentName.length() > 0) {
                logger.info("strComponentName: " + strComponentName);
                if (strComponentName.equalsIgnoreCase("Particle") && pregw != null) {
                  gw.setStrLabel(pregw.getStrLabel().trim() + "_" + strComponentName.trim());
                } else {
                  gw.setStrLabel(strComponentName);
                }

              } else {
                if (strGrammarRule != null && strGrammarRule.length() > 0) {
                  gw.setStrLabel(strGrammarRule);
                } else {
                  gw.setStrLabel("");
                  logger.error("error, along with no component name or grammar rule  ");
                }
              }

              if (gw.getIntType() == Lexicon.LEX_TYPE_VERB || gw.getIntType() == Lexicon.LEX_TYPE_VERB_VI
                  || gw.getIntType() == Lexicon.LEX_TYPE_VERB_VT) {
                gw.setAction(Integer.toString(wordList.size() - i + 1));
              } else if (gw.getIntType() == Lexicon.LEX_TYPE_ADJECTIVE || gw.getIntType() == Lexicon.LEX_TYPE_ADJVERB) {
                gw.setAction(Integer.toString(wordList.size() - i + 1));
              }

              if (tempSentenceWord.word.type == CALL_lexiconStruct.LEX_TYPE_VERB) {
                // first make sure which of these four are changable
                // int sign = tempSentenceWord.sign;
                // int tense = tempSentenceWord.tense;
                // int politeness = tempSentenceWord.politeness;
                // int question = tempSentenceWord.question;
                if (tempSentenceWord.tense == 1) {
                  tense = true;
                }
                if (tempSentenceWord.sign == 1) {
                  booNegative = false;
                } else {
                  booNegative = true;
                }
                logger.debug("a verb, booNegative: " + booNegative + " tense: " + tense + " politenes: " + politeness
                    + " question: " + question);
                String strTransformRule = tempSentenceWord.transformationRule;
                if (strTransformRule != null && strTransformRule.length() > 0) {
                  logger.debug("strTransformRule: " + strTransformRule + " word: " + tempSentenceWord.word.kanji);
                  gw.setStrTransformRule(strTransformRule);
                }

                try {
                  // get the predicted words, then add to the network;
                  Vector v = pp.getVerbError(lwm, lessonNum, tense, booNegative);
                  logger.info("getVerbError size : " + v.size());
                  for (int j = 0; j < v.size(); j++) {
                    EPLeaf epl = new EPLeaf();
                    String str = (String) v.elementAt(j);
                    // for verb, we need not to find the orignal word in the
                    // lexicon
                    // LexiconWordMeta lwmWord = lp.getLexiconWordVerb(str,
                    // lessonNum);
                    // if(lwmWord!=null){
                    // epl.setStrKana(lwmWord.getStrKana());
                    // epl.setStrKanji(lwmWord.getStrKanji());
                    // epl.setId(lwm.getId());
                    epl.setStrKana(str);
                    epl.setStrKanji(str);
                    logger.debug("Verb Error [" + j + "] is " + str);
                    /*
                     * }else{ epl.setStrKana(str); epl.setStrKanji(str);
                     * System.out.println("just add it, an error word: "+str);
                     * 
                     * }
                     */
                    gw.addSubsWord(epl);
                  }
                  // network.addElement(gw);
                } catch (IOException e) {
                  // TODO Auto-generated catch block
                  e.printStackTrace();
                  logger.error("IOException");
                }

              } else if (tempSentenceWord.word.type == CALL_lexiconStruct.LEX_TYPE_NOUN_NUMERAL) {

                try {
                  // get the predicted words, then add to the network;
                  Vector v = pp.getNQError(lwm, lessonNum);
                  logger.info("getNQError size : " + v.size());
                  for (int j = 0; j < v.size(); j++) {
                    EPLeaf epl = new EPLeaf();
                    String str = (String) v.elementAt(j);
                    LexiconWordMeta lwmWord = lp.getNQ(str);
                    if (lwmWord != null) {
                      epl.setStrKana(lwmWord.getStrKana());
                      epl.setStrKanji(lwmWord.getStrKanji());
                      epl.setId(lwm.getId());
                      logger.debug("Digit Error [" + j + "] is " + lwmWord.getStrKanji());
                    } else {
                      epl.setStrKana(str);
                      epl.setStrKanji(str);
                      logger.debug("just add it, Digit Error [" + j + "] " + str);
                    }
                    gw.addSubsWord(epl);
                  }
                  // network.addElement(gw);
                } catch (IOException e) {
                  // TODO Auto-generated catch block
                  e.printStackTrace();
                }
              } else if (tempSentenceWord.word.type == CALL_lexiconStruct.LEX_TYPE_PARTICLE_AUXIL) {

                try {
                  // get the predicted words, then add to the network;
                  Vector v = pp.getParticleError(lwm, lessonNum);
                  logger.info("getParticleError size : " + v.size());
                  for (int j = 0; j < v.size(); j++) {
                    EPLeaf epl = new EPLeaf();
                    String str = (String) v.elementAt(j);
                    LexiconWordMeta lwmWord = lp.getLexiconWordParticle(str);
                    if (lwmWord != null) {
                      epl.setStrKana(lwmWord.getStrKana());
                      epl.setStrKanji(lwmWord.getStrKanji());
                      epl.setId(lwm.getId());
                      epl.setIntType(lwm.getIntType());
                      logger.debug("PARTICLES Error [" + j + "] is " + lwmWord.getStrKanji());
                    } else {
                      epl.setStrKana(str);
                      epl.setStrKanji(str);
                      epl.setIntType(Lexicon.LEX_TYPE_PARTICLE_AUXIL);
                      logger.debug("just add it, PARTICLES Error [" + j + "] " + str);
                    }
                    gw.addSubsWord(epl);
                  }
                  // network.addElement(gw);
                } catch (IOException e) {
                  // TODO Auto-generated catch block
                  e.printStackTrace();
                }
              } else {// the only possible is noun

                try {
                  // get the predicted words, then add to the network;
                  Vector v = pp.getNounError(lwm, lessonNum);
                  logger.info("getNounError size : " + v.size());
                  if (v != null && v.size() > 0) {
                    for (int j = 0; j < v.size(); j++) {
                      EPLeaf epl = new EPLeaf();
                      String str = (String) v.elementAt(j);
                      LexiconWordMeta lwmWord = lp.getLexiconWordNounFull(str);
                      if (lwmWord != null) {
                        epl.setStrKana(lwmWord.getStrKana());
                        epl.setStrKanji(lwmWord.getStrKanji());
                        epl.setId(lwm.getId());
                        epl.setIntType(lwmWord.getIntType());
                        logger.debug("Noun Error [" + j + "] is " + lwmWord.getStrKanji());

                      } else {
                        epl.setStrKana(str);
                        epl.setStrKanji(str);
                        logger.debug("just add it, Noun Error [" + j + "] " + str);

                      }
                      gw.addSubsWord(epl);
                    }
                  }

                } catch (IOException e) {
                  // TODO Auto-generated catch block
                  e.printStackTrace();
                }

              }

            } else {// end of if lwm
              logger.error(" not found the word in lexicon in CALL_SentenceGrammar");
            }
          }
          /*
           * end of coping with the target word Then for each word, add all
           * substitution words (on the basis of errorType, create errors or
           * extract from prediction file )
           */
        }

        pregw = gw;
        network.addElement(gw);

      }// end of for(wordlist)
    }
    // file
    try {
      // write to file
      writeVocaFile(lessonNum, wordList.size(), network, sentenceStr);
      writeGrammarFile(lessonNum, wordList.size(), network, sentenceStr);

    } catch (IOException e) {
      // TODO Auto-generated catch block
      e.printStackTrace();
    }

    // for test
    // String pathfile = JGRAMBASE +"\\"+CONTEXTFILENAME;
    // // String pathfile = PATH +"\\"+CONTEXTFILENAME;
    // String origGramfile = pathfile+".grammar";
    // System.out.println("origGramfile---"
    // + origGramfile);
    // File oneFile = new File(origGramfile);
    // System.out.println("oneFile---" + oneFile.getAbsolutePath());
    // if (!oneFile.exists()) {
    // System.out.println("the file do not exist, in CALL_sentenceGrammar ");
    // }else{
    // System.out.println("grammar file exist");
    // }

    // invoke the mkdfa
    MakeDFA dfa = new MakeDFA();
    // dfa.getDFAFile(pathfile);
    dfa.getDFAFile(CONTEXTFILENAME);

    // sentence.setVGWNetwork(network);

  }

  /*
   * all is same with oneSentenceGrammar, just have return value
   */

  public Vector sentenceGrammar(CALL_sentenceStruct sentence, int lessonNum) {

    // currentQuestion = new CALL_questionStruct(db, config, gconfig, lesson,
    // CALL_questionStruct.QTYPE_CONTEXT);
    LexiconProcess lp = null;
    PredictionProcess pp = null;
    try {
      pp = new PredictionProcess();
    } catch (IOException e1) {
      // TODO Auto-generated catch block
      e1.printStackTrace();
    }
    // LexiconWordMeta lwm = new LexiconWordMeta();
    // SentenceStatisticStructure sss = new SentenceStatisticStructure();

    try {
      lp = new LexiconProcess();
    } catch (IOException e) {
      // TODO Auto-generated catch block
      e.printStackTrace();
    }
    boolean booNegative = false;
    boolean tense = false;
    boolean politeness = false;
    boolean question = false;
    Vector wordList;
    String sentenceStr;
    CALL_sentenceWordStruct tempSentenceWord;

    // print the top sentence
    sentenceStr = sentence.getSentenceString(CALL_io.kanji);
    // it is the top sentence, using same function with the hintsStruct

    wordList = sentence.getSentenceWords();
    if (wordList != null) {
      network = new Vector();
      System.out.println("target sentence is " + sentenceStr + " word size is: " + wordList.size());
      for (int i = 0; i < wordList.size(); i++) {
        tempSentenceWord = (CALL_sentenceWordStruct) wordList.elementAt(i);
        gw = new GrammarWord();
        CALL_wordStruct tempWord;
        if (tempSentenceWord != null) {
          // tempSentenceWord.print_debug();
          if (tempSentenceWord.word != null) {

            String word = tempSentenceWord.word.kanji;
            logger.debug("word " + i + ", kanji is " + word);
            gw.toEPWord(tempSentenceWord.word);

            // set id
            logger.debug("gw.getIntType(): " + gw.getIntType() + " kanji: " + gw.getStrKanji() + " StrEngKana: "
                + gw.getStrEngKana());

            LexiconWordMeta lwm = lp.getWord(gw.getIntType(), gw.getStrKanji(), gw.getStrEngKana());
            if (lwm == null) {
              lwm = lp.getWord(gw.getStrKanji(), gw.getStrEngKana());
            }
            if (lwm != null) {
              logger.debug("find target word in the lexicon");
              gw.setId(lwm.getId());
              // handle altKana
              String altKana = lwm.getStrAltkana();
              if (altKana != null && altKana.length() > 0) {
                int intKanaType = CharacterUtil.checkWordClass(altKana);
                if (intKanaType == CharacterUtil.TYPE_KATAKANA) {// katakana
                  gw.setStrEngKana(lwm.getStrAltkana());
                } else if (intKanaType == CharacterUtil.TYPE_HIRAGANA) {
                  gw.setStrAltKana(lwm.getStrAltkana());
                } else {
                  logger.error("altKana Type is not katakana or hiragana, but is  " + intKanaType);
                }
              }

              String strGrammarRule = tempSentenceWord.grammarRule;
              String strComponentName = tempSentenceWord.componentName;
              String strComponentLabel;
              if (strComponentName != null && strComponentName.length() > 0) {
                // check if this ComponentName has whitespace
                StringTokenizer st = new StringTokenizer(strComponentName);
                String str1 = "";
                String str2 = "";
                if (st.hasMoreElements()) {
                  str1 = (String) st.nextElement();
                } else {
                  logger.error("strComponentName is not null,but return no string");
                }
                if (st.hasMoreElements()) {
                  str2 = (String) st.nextElement();
                  if (str1.length() >= str2.length()) {
                    strComponentLabel = str1;
                  } else {
                    strComponentLabel = str2;
                  }
                } else {
                  strComponentLabel = strComponentName;
                }

                logger.debug("strComponentName: " + strComponentName);
                if (strComponentName.equalsIgnoreCase("Particle") && pregw != null) {
                  gw.setStrLabel(pregw.getStrLabel().trim() + "_" + strComponentLabel.trim());
                } else {
                  gw.setStrLabel(strComponentLabel);
                }

              } else {
                if (strGrammarRule != null && strGrammarRule.length() > 0) {
                  gw.setStrLabel(strGrammarRule);
                } else {
                  gw.setStrLabel("");
                  logger.error("error, along with no grammar rule ");
                }
              }

              if (gw.getIntType() == Lexicon.LEX_TYPE_VERB || gw.getIntType() == Lexicon.LEX_TYPE_VERB_VI
                  || gw.getIntType() == Lexicon.LEX_TYPE_VERB_VT) {
                gw.setAction(Integer.toString(wordList.size() - i + 1));
              } else if (gw.getIntType() == Lexicon.LEX_TYPE_ADJECTIVE || gw.getIntType() == Lexicon.LEX_TYPE_ADJVERB) {
                gw.setAction(Integer.toString(wordList.size() - i + 1));
              }

              if (tempSentenceWord.word.type == CALL_lexiconStruct.LEX_TYPE_VERB) {
                // first make sure which of these four are changable
                // int sign = tempSentenceWord.sign;
                // int tense = tempSentenceWord.tense;
                // int politeness = tempSentenceWord.politeness;
                // int question = tempSentenceWord.question;

                if (tempSentenceWord.tense == 1) {
                  tense = true;
                }
                if (tempSentenceWord.sign == 1) {
                  booNegative = false;
                } else {
                  booNegative = true;
                }
                logger.debug("a verb, booNegative: " + booNegative + " tense: " + tense + " politenes: " + politeness
                    + " question: " + question);
                String strTransformRule = tempSentenceWord.transformationRule;
                if (strTransformRule != null && strTransformRule.length() > 0) {
                  logger.debug("strTransformRule: " + strTransformRule + " word: " + tempSentenceWord.word.kanji);
                  gw.setStrTransformRule(strTransformRule);
                }

                try {
                  // get the predicted words, then add to the network;
                  Vector v = pp.getVerbError(lwm, lessonNum, tense, booNegative);
                  logger.debug("getVerbError size : " + v.size());
                  for (int j = 0; j < v.size(); j++) {
                    EPLeaf epl = new EPLeaf();
                    String str = (String) v.elementAt(j);
                    // for verb, we need not to find the orignal word in the
                    // lexicon
                    // LexiconWordMeta lwmWord = lp.getLexiconWordVerb(str,
                    // lessonNum);
                    // if(lwmWord!=null){
                    // epl.setStrKana(lwmWord.getStrKana());
                    // epl.setStrKanji(lwmWord.getStrKanji());
                    // epl.setId(lwm.getId());
                    epl.setStrKana(str);
                    epl.setStrKanji(str);
                    /*
                     * }else{ epl.setStrKana(str); epl.setStrKanji(str);
                     * System.out.println("just add it, an error word: "+str);
                     * 
                     * }
                     */
                    gw.addSubsWord(epl);
                  }
                  // network.addElement(gw);
                } catch (IOException e) {
                  // TODO Auto-generated catch block
                  logger.error("IOException");
                  e.printStackTrace();

                }

              } else if (tempSentenceWord.word.type == CALL_lexiconStruct.LEX_TYPE_NOUN_NUMERAL) {

                try {
                  // get the predicted words, then add to the network;
                  Vector v = pp.getNQError(lwm, lessonNum);
                  logger.debug("getNQError size : " + v.size());
                  for (int j = 0; j < v.size(); j++) {
                    EPLeaf epl = new EPLeaf();
                    String str = (String) v.elementAt(j);
                    LexiconWordMeta lwmWord = lp.getNQ(str);
                    if (lwmWord != null) {
                      epl.setStrKana(lwmWord.getStrKana());
                      epl.setStrKanji(lwmWord.getStrKanji());
                      epl.setId(lwm.getId());
                    } else {
                      epl.setStrKana(str);
                      epl.setStrKanji(str);
                      System.out.println("just add it, an error word: " + str);
                    }
                    gw.addSubsWord(epl);
                  }
                  // network.addElement(gw);
                } catch (IOException e) {
                  // TODO Auto-generated catch block
                  e.printStackTrace();
                }
              } else if (tempSentenceWord.word.type == CALL_lexiconStruct.LEX_TYPE_PARTICLE_AUXIL) {

                try {
                  // get the predicted words, then add to the network;
                  Vector v = pp.getParticleError(lwm, lessonNum);
                  logger.debug("getParticleError size : " + v.size());
                  for (int j = 0; j < v.size(); j++) {
                    EPLeaf epl = new EPLeaf();
                    String str = (String) v.elementAt(j);
                    LexiconWordMeta lwmWord = lp.getLexiconWordParticle(str);
                    if (lwmWord != null) {
                      epl.setStrKana(lwmWord.getStrKana());
                      epl.setStrKanji(lwmWord.getStrKanji());
                      epl.setId(lwm.getId());
                      epl.setIntType(lwm.getIntType());
                    } else {
                      epl.setStrKana(str);
                      epl.setStrKanji(str);
                      epl.setIntType(Lexicon.LEX_TYPE_PARTICLE_AUXIL);
                      logger.debug("just add it, an error word: " + str);
                    }
                    gw.addSubsWord(epl);
                  }
                  // network.addElement(gw);
                } catch (IOException e) {
                  // TODO Auto-generated catch block
                  e.printStackTrace();
                }
              } else {// the only possible is noun

                try {
                  // get the predicted words, then add to the network;
                  Vector v = pp.getNounError(lwm, lessonNum);
                  logger.debug("getNounError size : " + v.size());
                  if (v != null && v.size() > 0) {
                    for (int j = 0; j < v.size(); j++) {
                      EPLeaf epl = new EPLeaf();
                      String str = (String) v.elementAt(j);
                      LexiconWordMeta lwmWord = lp.getLexiconWordNounFull(str);
                      if (lwmWord != null) {
                        epl.setStrKana(lwmWord.getStrKana());
                        epl.setStrKanji(lwmWord.getStrKanji());
                        epl.setId(lwm.getId());
                        epl.setIntType(lwmWord.getIntType());

                      } else {
                        epl.setStrKana(str);
                        epl.setStrKanji(str);
                        logger.debug("just add it, an error word: " + str);

                      }
                      gw.addSubsWord(epl);
                    }
                  }

                } catch (IOException e) {
                  // TODO Auto-generated catch block
                  e.printStackTrace();
                }

              }

            } else {// end of if lwm
              logger.error(" not found the word in lexicon in CALL_SentenceGrammar");
            }
          }

          /*
           * end of coping with the target word Then for each word, add all
           * substitution words (on the basis of errorType, create errors or
           * extract from prediction file )
           */

          // lessonNum
        }

        pregw = gw;
        network.addElement(gw);

      }// end of for(wordlist)
    }
    // file
    try {
      // write to file
      writeVocaFile(lessonNum, wordList.size(), network, sentenceStr);
      writeGrammarFile(lessonNum, wordList.size(), network, sentenceStr);

    } catch (IOException e) {
      // TODO Auto-generated catch block
      e.printStackTrace();
    }

    // invoke the mkdfa
    MakeDFA dfa = new MakeDFA();
    // dfa.getDFAFile(pathfile);
    dfa.getDFAFile(CONTEXTFILENAME);
    // sentence.setVGWNetwork(network);

    return network;
  }

  /*
   * all is same with sentenceGrammar, just have error type info
   */
  public Vector sentenceGrammars(CALL_sentenceStruct sentence, int lessonNum) {

    // currentQuestion = new CALL_questionStruct(db, config, gconfig, lesson,
    // CALL_questionStruct.QTYPE_CONTEXT);
    LexiconProcess lp = null;
    PredictionProcess pp = null;
    try {
      pp = new PredictionProcess();
    } catch (IOException e1) {
      // TODO Auto-generated catch block
      e1.printStackTrace();
    }
    // LexiconWordMeta lwm = new LexiconWordMeta();
    // SentenceStatisticStructure sss = new SentenceStatisticStructure();

    try {
      lp = new LexiconProcess();
    } catch (IOException e) {
      // TODO Auto-generated catch block
      e.printStackTrace();
    }
    boolean booNegative = false;
    boolean tense = false;
    boolean politeness = false;
    boolean question = false;
    Vector wordList;
    String sentenceStr;
    CALL_sentenceWordStruct tempSentenceWord;

    // print the top sentence
    sentenceStr = sentence.getSentenceString(CALL_io.kanji);
    // it is the top sentence, using same function with the hintsStruct

    wordList = sentence.getSentenceWords();
    if (wordList != null) {
      network = new Vector();
      logger.info("target sentence is " + sentenceStr + " word size is: " + wordList.size());
      for (int i = 0; i < wordList.size(); i++) {
        tempSentenceWord = (CALL_sentenceWordStruct) wordList.elementAt(i);
        gw = new GrammarWord();
        CALL_wordStruct tempWord;
        if (tempSentenceWord != null) {
          // tempSentenceWord.print_debug();
          if (tempSentenceWord.word != null) {

            String word = tempSentenceWord.word.kanji;
            logger.info("word " + i + ", kanji is " + word);
            gw.toEPWord(tempSentenceWord.word);

            // set id
            logger.debug("gw.getIntType(): " + gw.getIntType() + " kanji: " + gw.getStrKanji() + " StrEngKana: "
                + gw.getStrEngKana());

            LexiconWordMeta lwm = lp.getWord(gw.getIntType(), gw.getStrKanji(), gw.getStrKana());
            if (lwm == null) {
              lwm = lp.getWord(gw.getStrKanji(), gw.getStrEngKana());
            }
            if (lwm != null) {
              logger.debug("find target word in the lexicon");
              gw.setId(lwm.getId());
              // handle altKana
              String altKana = lwm.getStrAltkana();
              if (altKana != null && altKana.length() > 0) {
                int intKanaType = CharacterUtil.checkWordClass(altKana);
                if (intKanaType == CharacterUtil.TYPE_KATAKANA) {// katakana
                  gw.setStrEngKana(lwm.getStrAltkana());
                } else if (intKanaType == CharacterUtil.TYPE_HIRAGANA) {
                  gw.setStrAltKana(lwm.getStrAltkana());
                } else {
                  logger.error("altKana Type is not katakana or hiragana, but is  " + intKanaType);
                }
              }

              String strGrammarRule = tempSentenceWord.grammarRule;
              String strComponentName = tempSentenceWord.componentName;
              String strComponentLabel;
              if (strComponentName != null && strComponentName.length() > 0) {
                // check if this ComponentName has whitespace
                StringTokenizer st = new StringTokenizer(strComponentName);
                String str1 = "";
                String str2 = "";
                if (st.hasMoreElements()) {
                  str1 = (String) st.nextElement();
                } else {
                  logger.error("strComponentName is not null,but return no string");
                }
                if (st.hasMoreElements()) {
                  str2 = (String) st.nextElement();
                  if (str1.length() >= str2.length()) {
                    strComponentLabel = str1;
                  } else {
                    strComponentLabel = str2;
                  }
                } else {
                  strComponentLabel = strComponentName;
                }

                logger.debug("strComponentName: " + strComponentName);
                if (strComponentName.equalsIgnoreCase("Particle") && pregw != null) {
                  gw.setStrLabel(pregw.getStrLabel().trim() + "_" + strComponentLabel.trim());
                } else {
                  gw.setStrLabel(strComponentLabel);
                }

              } else {
                if (strGrammarRule != null && strGrammarRule.length() > 0) {
                  gw.setStrLabel(strGrammarRule);
                } else {
                  gw.setStrLabel("");
                  logger.error("error, along with no grammar rule ");
                }
              }

              if (gw.getIntType() == Lexicon.LEX_TYPE_VERB || gw.getIntType() == Lexicon.LEX_TYPE_VERB_VI
                  || gw.getIntType() == Lexicon.LEX_TYPE_VERB_VT) {
                gw.setAction(Integer.toString(wordList.size() - i + 1));
              } else if (gw.getIntType() == Lexicon.LEX_TYPE_ADJECTIVE || gw.getIntType() == Lexicon.LEX_TYPE_ADJVERB) {
                gw.setAction(Integer.toString(wordList.size() - i + 1));
              }

              if (tempSentenceWord.word.type == CALL_lexiconStruct.LEX_TYPE_VERB) {
                // first make sure which of these four are changable
                // int sign = tempSentenceWord.sign;
                // int tense = tempSentenceWord.tense;
                // int politeness = tempSentenceWord.politeness;
                // int question = tempSentenceWord.question;

                if (tempSentenceWord.tense == 1) {
                  tense = true;
                }
                if (tempSentenceWord.sign == 1) {
                  booNegative = false;
                } else {
                  booNegative = true;
                }
                logger.debug("a verb, booNegative: " + booNegative + " tense: " + tense + " politenes: " + politeness
                    + " question: " + question);
                String strTransformRule = tempSentenceWord.transformationRule;
                if (strTransformRule != null && strTransformRule.length() > 0) {
                  logger.debug("strTransformRule: " + strTransformRule + " word: " + tempSentenceWord.word.kanji);
                  gw.setStrTransformRule(strTransformRule);
                }

                try {
                  // get the predicted words, then add to the network;
                  Vector v = pp.getVerbErrors(lwm, lessonNum, tense, booNegative);
                  logger.debug("getVerbErrors size : " + v.size());
                  // logger.debug(lwm.getStrKanji() + ", Errors's size:"+
                  // v.size());
                  for (int j = 0; j < v.size(); j++) {
                    EPLeaf epl = (EPLeaf) v.elementAt(j);
                    // for verb, we need not to find the orignal word in the
                    // lexicon
                    // LexiconWordMeta lwmWord = lp.getLexiconWordVerb(str,
                    // lessonNum);

                    // epl.setStrKana(str);
                    // epl.setStrKanji(str);

                    gw.addSubsWord(epl);
                  }
                  // network.addElement(gw);
                } catch (IOException e) {
                  // TODO Auto-generated catch block
                  logger.error("IOException");
                  e.printStackTrace();

                }

              } else if (tempSentenceWord.word.type == CALL_lexiconStruct.LEX_TYPE_NOUN_NUMERAL) {

                try {
                  // get the predicted words, then add to the network;
                  Vector v = pp.getNQErrors(lwm, lessonNum);
                  logger.debug("getNQErrors size : " + v.size());
                  // logger.debug(lwm.getStrKanji() + ", Errors's size:"+
                  // v.size());
                  for (int j = 0; j < v.size(); j++) {
                    EPLeaf epl = (EPLeaf) v.elementAt(j);
                    // LexiconWordMeta lwmWord = lp.getNQ(str);
                    // if(lwmWord!=null){
                    // epl.setStrKana(lwmWord.getStrKana());
                    // epl.setStrKanji(lwmWord.getStrKanji());
                    // epl.setId(lwm.getId());
                    // }else{
                    // epl.setStrKana(str);
                    // epl.setStrKanji(str);
                    // System.out.println("just add it, an error word: "+str);
                    // }
                    gw.addSubsWord(epl);
                  }
                  // network.addElement(gw);
                } catch (IOException e) {
                  // TODO Auto-generated catch block
                  e.printStackTrace();
                }
              } else if (tempSentenceWord.word.type == CALL_lexiconStruct.LEX_TYPE_PARTICLE_AUXIL) {

                try {
                  // get the predicted words, then add to the network;
                  Vector v = pp.getParticleErrors(lwm, lessonNum);
                  logger.debug(lwm.getStrKanji() + ", Errors's size:" + v.size());
                  for (int j = 0; j < v.size(); j++) {
                    EPLeaf epl = (EPLeaf) v.elementAt(j);
                    // LexiconWordMeta lwmWord = lp.getLexiconWordParticle(str);
                    // if(lwmWord!=null){
                    // epl.setStrKana(lwmWord.getStrKana());
                    // epl.setStrKanji(lwmWord.getStrKanji());
                    // epl.setId(lwm.getId());
                    // epl.setIntType(lwm.getIntType());
                    // }else{
                    // epl.setStrKana(str);
                    // epl.setStrKanji(str);
                    // epl.setIntType(Lexicon.LEX_TYPE_PARTICLE_AUXIL);
                    // logger.debug("just add it, an error word: "+str);
                    // }
                    gw.addSubsWord(epl);
                  }
                  // network.addElement(gw);
                } catch (IOException e) {
                  // TODO Auto-generated catch block
                  e.printStackTrace();
                }
              } else {// the only possible is noun

                try {
                  // get the predicted words, then add to the network;
                  Vector v = pp.getNounErrors(lwm, lessonNum);
                  logger.debug(lwm.getStrKanji() + ", Errors's size:" + v.size());
                  if (v != null && v.size() > 0) {
                    for (int j = 0; j < v.size(); j++) {
                      EPLeaf epl = (EPLeaf) v.elementAt(j);
                      // LexiconWordMeta lwmWord =
                      // lp.getLexiconWordNounFull(str);
                      // if(lwmWord!=null){
                      // epl.setStrKana(lwmWord.getStrKana());
                      // epl.setStrKanji(lwmWord.getStrKanji());
                      // epl.setId(lwm.getId());
                      // epl.setIntType(lwmWord.getIntType());
                      //
                      // }else{
                      // epl.setStrKana(str);
                      // epl.setStrKanji(str);
                      // logger.debug("just add it, an error word: "+str);
                      //
                      // }
                      gw.addSubsWord(epl);
                    }
                  }

                } catch (IOException e) {
                  // TODO Auto-generated catch block
                  e.printStackTrace();
                }

              }

            } else {// end of if lwm
              logger.error(" not found the word in CALL_SentenceGrammar: " + word);
            }
          }

          /*
           * end of coping with the target word Then for each word, add all
           * substitution words (on the basis of errorType, create errors or
           * extract from prediction file )
           */

          // lessonNum
        }

        pregw = gw;
        network.addElement(gw);

      }// end of for(wordlist)
    }
    // file
    try {
      // write to file
      writeVocaFile(lessonNum, wordList.size(), network, sentenceStr);
      writeGrammarFile(lessonNum, wordList.size(), network, sentenceStr);

    } catch (IOException e) {
      // TODO Auto-generated catch block
      e.printStackTrace();
    }

    // invoke the mkdfa
    MakeDFA dfa = new MakeDFA();
    // dfa.getDFAFile(pathfile);
    dfa.getDFAFile(CONTEXTFILENAME);
    // sentence.setVGWNetwork(network);

    return network;
  }

  public void sentenceGrammar4GeneralMethod(String DBTableName) throws NumberFormatException, SQLException, IOException {

    String strOdbc = FindConfig.getConfig().findStr(NewLogParser.OdbcName);
    dm.connectToAccess(strOdbc);

    String sql = "SELECT * FROM " + DBTableName;
    ResultSet rs = dm.executeQuery(sql);

    while (rs.next()) {// still remains sentences
      int intId = rs.getInt("ID");
      String strLesson = rs.getString("Lesson");
      int intLesson = Integer.parseInt(strLesson.trim());
      String strTargetSentence = rs.getString("strTargetAnswer");
      if (intId > 33) {
        logger.info("ID: " + intId + " target sentence: " + strTargetSentence);

        sentenceGrammar4GeneralMethod(strTargetSentence, intId, intLesson);

        // create the bat file in "C:\eclipse\workspace\JCALLSpokenExercise"

        // writebatFile(name);
      }

    }

    dm.releaseConn();

  }

  public Vector getSetenceFromTable(String tablename) {

    String strOdbc = FindConfig.getConfig().findStr(NewLogParser.OdbcName);
    dm.connectToAccess(strOdbc);

    Vector<SentenceDataMeta> v = new Vector<SentenceDataMeta>();
    // read data into WordErrDataMeta one by one, change attribute on the basis
    // of its type
    try {

      SentenceDataMeta objMeta;
      ResultSet tmpRs = dm.searchTable(tablename, "");
      while (tmpRs.next()) {
        // objEDMeta.intID = tmpRs.getInt("ID");
        int iD = tmpRs.getInt("ID");
        int studentID = tmpRs.getInt("StudentID");
        String lesson = tmpRs.getString("Lesson");
        String strQuestion = tmpRs.getString("Question");
        String strTargetWord = tmpRs.getString("strTargetAnswer");
        String strRecognitionWord = tmpRs.getString("strSpeechAnswer");
        String strListenWord = tmpRs.getString("strListeningAnswer");
        // System.out.println("Question: "+ strQuestion);
        objMeta = new SentenceDataMeta(iD, studentID, lesson, strQuestion, strTargetWord, strListenWord,
            strRecognitionWord);

        logger.debug("Draw sentence: " + strTargetWord);
        v.addElement(objMeta);
      }// end while

    } catch (Exception e) {
      System.out.println("Exception in wrongTypeProcess of CBPManager " + e.getMessage());
      e.printStackTrace();
    }
    dm.releaseConn();

    return v;
  }

  /*
   * all is same with sentenceGrammar, just have error type info
   */
  public void sentenceGrammar4GeneralMethod(String targetSentence, int intID, int lessonNum) throws IOException {

    JulianGram jg = new JulianGram();
    Vector<GrammarWord> grammarnetwork = new Vector();
    // LexiconProcess lp = null;
    // PredictionProcess pp = null;
    int intIndex = 0;
    StringTokenizer st;
    boolean booVerb = false;
    boolean booParticle = false;
    LexiconWordMeta lwm;

    // try {
    // System.out.println("start new PredictionProcess()");
    // pp = new PredictionProcess();
    // } catch (IOException e1) {
    // // TODO Auto-generated catch block
    // e1.printStackTrace();
    // }
    // try {
    // lp = new LexiconProcess();
    // } catch (IOException e) {
    // // TODO Auto-generated catch block
    // e.printStackTrace();
    // }

    Vector wordList;
    String sentenceStr;
    String strWord = "";
    CALL_sentenceWordStruct tempSentenceWord;
    int errorWord = 0;
    HashSet<String> hs;
    // print the top sentence
    sentenceStr = targetSentence;
    // it is the top sentence, using same function with the hintsStruct
    st = new StringTokenizer(targetSentence);
    intIndex = 0;
    while (st.hasMoreTokens()) { // handle word
      intIndex++;
      strWord = st.nextToken();
      strWord = strWord.trim();
      // First, get word type;
      if (st.hasMoreTokens()) {
        booVerb = false;
        if (intIndex % 2 == 0) {// = particle
          booParticle = true;
          lwm = lp.getLexiconWordParticle(strWord);
          if (lwm != null) {
            gw = new GrammarWord();
            gw.setIntType(lwm.getIntType());
            gw.setStrKana(lwm.getStrKana());
            gw.setStrKanji(lwm.getStrKanji());
            gw.setStrLabel("PARTICLE_" + intIndex);
            for (int i = 0; i < particle.length; i++) {
              String str = particle[i];
              // LexiconWordMeta lwmTemp = lp.getLexiconWordParticle(str);
              EPLeaf epl = new EPLeaf();
              epl.setStrKana(str);
              epl.setStrKanji(str);
              epl.setIntType(6);
              gw.addSubsWord(epl);

            }
            grammarnetwork.add(gw);
            logger.debug("getParticleErrorNumber: 11");
          } else {
            errorWord++;
            logger.error("wrong,target particle not exist in db ---[" + strWord + "]" + "in sentence " + intID
                + " in lesson " + lessonNum);
          }

        } else {// noun+NQ
          booParticle = false;
          lwm = lp.getLexiconWordNoun(strWord);
          if (lwm != null) { // type = noun
          // noun++;
            gw = new GrammarWord();
            gw.setIntType(lwm.getIntType());
            gw.setStrKana(lwm.getStrKana());
            gw.setStrKanji(lwm.getStrKanji());
            gw.setStrLabel("NOUN_" + intIndex);
            // Vector vec = jg.getConceptVector(lessonNum-1,
            // lwm.getStrKanji(),lwm.getStrKana());

            Vector vec = jg.getConceptVector(lessonNum - 1, strWord, strWord);

            if (vec != null && vec.size() > 0) {
              hs = new HashSet();
              for (int i = 0; i < vec.size(); i++) {
                CALL_wordStruct callword = (CALL_wordStruct) vec.elementAt(i);
                // LexiconWordMeta lwmTemp = lp.getLexiconWordParticle(str);
                if (!hs.contains(callword.kana)) {
                  hs.add(callword.kana);
                  EPLeaf epl = new EPLeaf();
                  epl.setStrKana(callword.kana);
                  epl.setStrKanji(callword.kanji);
                  epl.setIntType(1);
                  gw.addSubsWord(epl);
                }
                // add alternative words of this words
                Vector vAltKana = callword.getAltKana();
                Vector vAltKanji = callword.getAltKanji();
                for (int j = 0; j < vAltKana.size(); j++) {
                  String str = (String) vAltKana.elementAt(j);
                  logger.debug("AltKana[" + j + "]: " + str);
                  if (!hs.contains(str)) {
                    hs.add(str);
                    EPLeaf epl = new EPLeaf();
                    epl.setStrKana(str);
                    epl.setStrKanji((String) vAltKanji.elementAt(j));
                    epl.setIntType(1);
                    gw.addSubsWord(epl);
                  }
                }
              }// end of for vec
            } else {
              logger.error("no substitute word");
            }
            grammarnetwork.add(gw);
            // logger.debug("getNounErrorNumber: "+vec.size());
          } else {
            errorWord++;
            logger.error("wrong,target noun/NQ not exist in db ---[" + strWord + "]" + "in sentence " + intID
                + " in lesson " + lessonNum);
          }
        }
      } else {
        booVerb = true;
        lwm = lp.getLexiconWordVerb(strWord, lessonNum);
        if (lwm != null) {
          // int a = pp.getVerbError_VS_DFORM(lwm, intLesson, sss);
          gw = new GrammarWord();
          gw.setIntType(lwm.getIntType());
          gw.setStrKana(lwm.getStrKana());
          gw.setStrKanji(lwm.getStrKanji());
          gw.setStrLabel("VERB");
          Vector vec = pp.getVerbError_VS_DFORM(lwm, lessonNum);
          if (vec != null && vec.size() > 0) {
            for (int i = 0; i < vec.size(); i++) {
              String strword = (String) vec.elementAt(i);
              // LexiconWordMeta lwmTemp = lp.getLexiconWordParticle(str);
              EPLeaf epl = new EPLeaf();
              epl.setStrKana(strword);
              epl.setStrKanji(strword);
              epl.setIntType(2);
              gw.addSubsWord(epl);
            }
          } else {
            logger.error("no substitute word");
          }

          grammarnetwork.add(gw);
          // logger.debug("getVerbErrorNumber: "+vec.size());
        } else {
          errorWord++;
          logger.error("wrong,target verb not exist in db ---[" + strWord + "]" + "in sentence " + intID
              + " in lesson " + lessonNum);
        }
      }
    }// end of while st
    // file
    try {
      // write to file
      String name = new String("NO") + intID;
      logger.info("network componentsize: " + network.size());
      writeVocaFile(lessonNum, intIndex, grammarnetwork, sentenceStr, name);
      writeGrammarFile(lessonNum, intIndex, grammarnetwork, sentenceStr, name);

    } catch (IOException e) {
      // TODO Auto-generated catch block
      e.printStackTrace();
    }

    // invoke the mkdfa
    MakeDFA dfa = new MakeDFA();
    // dfa.getDFAFile(pathfile);
    String name = new String("NO") + intID;
    dfa.getDFAFile(name);
    writebatFile(name);
    // return network;
  }

  /*
   * method is 0,1,2,3,4 4 is proposed method
   */

  public void sentenceGrammar4Method(String tablename, int method) throws NumberFormatException, SQLException,
      IOException {

    Vector v = getSetenceFromTable(tablename);
    for (int i = 0; i < v.size(); i++) {
      SentenceDataMeta objMeta = (SentenceDataMeta) v.elementAt(i);
      String targetSen = objMeta.getStrTargetSentence();

    }

    String strOdbc = FindConfig.getConfig().findStr(NewLogParser.OdbcName);
    dm.connectToAccess(strOdbc);

    String sql = "SELECT * FROM " + tablename;
    ResultSet rs = dm.executeQuery(sql);

    while (rs.next()) {// still remains sentences
      int intId = rs.getInt("ID");
      String strLesson = rs.getString("Lesson");
      int intLesson = Integer.parseInt(strLesson.trim());
      String strTargetSentence = rs.getString("strTargetAnswer");
      if (intId > 33) {
        logger.info("ID: " + intId + " target sentence: " + strTargetSentence);

        sentenceGrammar4GeneralMethod(strTargetSentence, intId, intLesson);

        // create the bat file in "C:\eclipse\workspace\JCALLSpokenExercise"

        // writebatFile(name);
      }

    }

    dm.releaseConn();

  }

  /*
   * all is same with sentenceGrammar, just have error type info
   */
  // public void sentenceGrammar4Method(String targetSentence, int intID,int
  // lessonNum,int method) throws IOException {
  //
  // JulianGram jg = new JulianGram();
  // Vector<GrammarWord> grammarnetwork = new Vector();
  // int intIndex = 0;
  // StringTokenizer st;
  // Vector wordList;
  // String sentenceStr;
  // String strWord ="";
  // CALL_sentenceWordStruct tempSentenceWord;
  // int errorWord=0;
  // HashSet<String> hs ;
  // //print the top sentence
  // sentenceStr = targetSentence;
  // //it is the top sentence, using same function with the hintsStruct
  // st= new StringTokenizer(targetSentence);
  // intIndex = 0;
  // while(st.hasMoreTokens()){ // handle word
  // intIndex++;
  // strWord = st.nextToken();
  // strWord = strWord.trim();
  //
  // //file
  // try {
  // //write to file
  // String name = new String("NO")+intID;
  // logger.info("network componentsize: "+ network.size());
  // writeVocaFile(lessonNum,intIndex,grammarnetwork,sentenceStr,name);
  // writeGrammarFile(lessonNum,intIndex,grammarnetwork,sentenceStr,name);
  //
  // } catch (IOException e) {
  // // TODO Auto-generated catch block
  // e.printStackTrace();
  // }
  //
  // // invoke the mkdfa
  // MakeDFA dfa = new MakeDFA();
  // //dfa.getDFAFile(pathfile);
  // String name = new String("NO")+intID;
  // dfa.getDFAFile(name);
  // writebatFile(name);
  // //return network;
  // }
  //
  //
  //

  public void writebatFile(String filename) throws IOException {

    String filepath = "C:\\eclipse\\workspace\\JCALLSpokenExercise\\";

    String bat = filename + ".bat";
    File batFile = new File(filepath, bat);
    // check file path and make dir,create new file
    File batpath = new File(filepath);
    if (!batpath.exists()) {
      batpath.mkdir();
    }
    if (batFile.exists()) {
      batFile.delete();
    }
    batFile.createNewFile();
    logger.debug("update all data,creat new file---" + batFile.getAbsolutePath());
    // save to file

    BufferedWriter vocaBW = new BufferedWriter(new FileWriter(batFile));
    if (vocaBW != null) {
      vocaBW.write("start julian\\bin\\julian.exe -C julian/hmm_ptm.jconf -dfa Data/JGrammar/" + filename
          + ".dfa -v Data/JGrammar/" + filename + ".dict -input rawfile -quiet");
      vocaBW.newLine();
      logger.info("start julian\\bin\\julian.exe -C julian/hmm_ptm.jconf -dfa Data/JGrammar/" + filename
          + ".dfa -v Data/JGrammar/" + filename + ".dict -input rawfile -quiet");
      vocaBW.flush();
      vocaBW.close();
    }

  }

  public void writeVocaFile(int lessonIndex, int sentenceListSize, Vector network, String correctAnswer)
      throws IOException {

    // file
    // grammarFileName = "\\L"+index+"\\L"+index+correctAnswer;
    // String filename = new String("L" + (lessonIndex));
    // String filename ="L"+lessonIndex+ correctAnswer;

    String filepath = JGRAMBASE + "\\";
    // String filepath = PATH + "\\" ;
    String voca = CONTEXTFILENAME + ".voca";
    File vocaFile = new File(filepath, voca);
    // check file path and make dir,create new file
    File vocaPath = new File(filepath);
    if (!vocaPath.exists()) {
      vocaPath.mkdir();
    }
    if (vocaFile.exists()) {
      vocaFile.delete();
    }
    vocaFile.createNewFile();
    logger.debug("update all data,creat new file---" + vocaFile.getAbsolutePath());
    // save to file

    BufferedWriter vocaBW = new BufferedWriter(new FileWriter(vocaFile));
    if (vocaBW != null) {
      if (network != null) {
        if (network.size() == sentenceListSize) {
          for (int i = 0; i < network.size(); i++) {
            GrammarWord gwTemp = (GrammarWord) network.elementAt(i);
            vocaBW.write("% " + gwTemp.getStrLabel());
            vocaBW.newLine();
            logger.info("% " + gwTemp.getStrLabel());
            Vector wordList = gwTemp.getVecSubsWord();
            for (int j = 0; j < wordList.size(); j++) {
              EPLeaf epl = (EPLeaf) wordList.elementAt(j);
              // String strKanji = epl.getStrKanji().trim() + STR_TAB;
              String strkana2 = epl.getStrKana().trim() + STR_TAB;
              String strkana = epl.getStrKana().trim();
              int intType = epl.getIntType();
              String strJulianSentence = strkana2 + CharacterUtil.wordKanaToJulianVoca(strkana, intType);
              vocaBW.write(strJulianSentence);
              vocaBW.newLine();
              logger.info(strJulianSentence);
            }
            String str = gwTemp.getStrEngKana();
            if (str != null && str.length() > 0) {
              // String strKanji = str.trim() + STR_TAB;
              String strkana2 = str.trim() + STR_TAB;
              String strkana = str.trim();
              int intType = gwTemp.getIntType();
              String strJulianSentence = strkana2 + CharacterUtil.wordKanaToJulianVoca(strkana, intType);
              vocaBW.write(strJulianSentence);
              vocaBW.newLine();
              logger.info(strJulianSentence);
            }

          }
          vocaBW.write("% NS_B");
          vocaBW.newLine();
          vocaBW.write("<s>	silB");
          vocaBW.newLine();
          vocaBW.write("% NS_E");
          vocaBW.newLine();
          vocaBW.write("</s>	silE");
          vocaBW.newLine();
          vocaBW.flush();
          vocaBW.close();
        }
      } else {
        System.out.println("network size is:" + network.size() + " not the same with sentenceListSize: "
            + sentenceListSize);
      }
    } else {
      System.out.println("network is null");
    }

  }

  public void writeGrammarFile(int lessonIndex, int sentenceListSize, Vector network, String correctAnswer)
      throws IOException {

    // file
    // String filename = new String("L" + (lessonIndex));
    String filepath = JGRAMBASE + "\\";
    // String filepath = PATH + "\\" ;
    String grammar = CONTEXTFILENAME + ".grammar";
    File gramFile = new File(filepath, grammar);
    // check file path and make dir,create new file
    if (true) {
      File vocaPath = new File(filepath);
      if (!vocaPath.exists()) {
        vocaPath.mkdir();
      }
      if (gramFile.exists()) {
        gramFile.delete();
      }
      gramFile.createNewFile();
      System.out.println("update all data,creat new file---" + gramFile.getAbsolutePath());

    }
    // save to file

    BufferedWriter gramBW = new BufferedWriter(new FileWriter(gramFile));

    if (network != null && network.size() == sentenceListSize) {
      if (network.size() == 1) {
        GrammarWord gwTemp = (GrammarWord) network.get(0);
        gramBW.write("S : NS_B " + gwTemp.getStrLabel() + " NS_E");
        gramBW.close();
      } else {
        for (int i = 0; i < network.size(); i++) {
          GrammarWord gwTemp = (GrammarWord) network.get(i);
          // single word;
          gramBW.write("S : NS_B " + gwTemp.getStrLabel() + " NS_E");
          gramBW.newLine();
        }
        // whole sentence
        gramBW.write("S : NS_B ");
        for (int i = 0; i < network.size(); i++) {
          GrammarWord gwTemp = (GrammarWord) network.get(i);
          // grammar file;
          gramBW.write(gwTemp.getStrLabel() + " ");
        }
        gramBW.write("NS_E");
        // close the file
        gramBW.close();
      }
    } // end of "if network!=null"

  }

  public void writeVocaFile(int lessonIndex, int sentenceListSize, Vector network, String correctAnswer, String filename)
      throws IOException {

    // file
    // grammarFileName = "\\L"+index+"\\L"+index+correctAnswer;
    // String filename = new String("L" + (lessonIndex));
    // String filename ="L"+lessonIndex+ correctAnswer;

    String filepath = JGRAMBASE + "\\";
    // String filepath = PATH + "\\" ;
    String voca = filename + ".voca";
    File vocaFile = new File(filepath, voca);
    // check file path and make dir,create new file
    File vocaPath = new File(filepath);
    if (!vocaPath.exists()) {
      vocaPath.mkdir();
    }
    if (vocaFile.exists()) {
      vocaFile.delete();
    }
    vocaFile.createNewFile();
    logger.debug("update all data,creat new file---" + vocaFile.getAbsolutePath());
    // save to file

    BufferedWriter vocaBW = new BufferedWriter(new FileWriter(vocaFile));
    if (vocaBW != null) {
      if (network != null) {
        if (network.size() == sentenceListSize) {
          for (int i = 0; i < network.size(); i++) {
            GrammarWord gwTemp = (GrammarWord) network.elementAt(i);
            vocaBW.write("% " + gwTemp.getStrLabel());
            vocaBW.newLine();
            logger.info("% " + gwTemp.getStrLabel());
            Vector wordList = gwTemp.getVecSubsWord();
            for (int j = 0; j < wordList.size(); j++) {
              EPLeaf epl = (EPLeaf) wordList.elementAt(j);
              // String strKanji = epl.getStrKanji().trim() + STR_TAB;
              String strkana2 = epl.getStrKana().trim() + STR_TAB;
              String strkana = epl.getStrKana().trim();
              int intType = epl.getIntType();
              String strJulianSentence = strkana2 + CharacterUtil.wordKanaToJulianVoca(strkana, intType);
              vocaBW.write(strJulianSentence);
              vocaBW.newLine();
              logger.info(strJulianSentence);
            }
            String str = gwTemp.getStrEngKana();
            if (str != null && str.length() > 0) {
              // String strKanji = str.trim() + STR_TAB;
              String strkana2 = str.trim() + STR_TAB;
              String strkana = str.trim();
              int intType = gwTemp.getIntType();
              String strJulianSentence = strkana2 + CharacterUtil.wordKanaToJulianVoca(strkana, intType);
              vocaBW.write(strJulianSentence);
              vocaBW.newLine();
              logger.info(strJulianSentence);
            }

          }
          vocaBW.write("% NS_B");
          vocaBW.newLine();
          vocaBW.write("<s>	silB");
          vocaBW.newLine();
          vocaBW.write("% NS_E");
          vocaBW.newLine();
          vocaBW.write("</s>	silE");
          vocaBW.newLine();

        }
      } else {
        System.out.println("network size is:" + network.size() + " not the same with sentenceListSize: "
            + sentenceListSize);
      }
      vocaBW.flush();
      vocaBW.close();

    } else {
      System.out.println("network is null");
    }

  }

  public void writeGrammarFile(int lessonIndex, int sentenceListSize, Vector network, String correctAnswer,
      String filename) throws IOException {

    // file
    // String filename = new String("L" + (lessonIndex));
    String filepath = JGRAMBASE + "\\";
    // String filepath = PATH + "\\" ;
    String grammar = filename + ".grammar";
    File gramFile = new File(filepath, grammar);
    // check file path and make dir,create new file
    if (true) {
      File vocaPath = new File(filepath);
      if (!vocaPath.exists()) {
        vocaPath.mkdir();
      }
      if (gramFile.exists()) {
        gramFile.delete();
      }
      gramFile.createNewFile();
      System.out.println("update all data,creat new file---" + gramFile.getAbsolutePath());

    }
    // save to file

    BufferedWriter gramBW = new BufferedWriter(new FileWriter(gramFile));

    if (network != null && network.size() == sentenceListSize) {
      if (network.size() == 1) {
        GrammarWord gwTemp = (GrammarWord) network.get(0);
        gramBW.write("S : NS_B " + gwTemp.getStrLabel() + " NS_E");
        gramBW.close();
      } else {
        for (int i = 0; i < network.size(); i++) {
          GrammarWord gwTemp = (GrammarWord) network.get(i);
          // single word;
          gramBW.write("S : NS_B " + gwTemp.getStrLabel() + " NS_E");
          gramBW.newLine();
        }
        // whole sentence
        gramBW.write("S : NS_B ");
        for (int i = 0; i < network.size(); i++) {
          GrammarWord gwTemp = (GrammarWord) network.get(i);
          // grammar file;
          gramBW.write(gwTemp.getStrLabel() + " ");
        }
        gramBW.write("NS_E");
        // close the file
        gramBW.close();
      }
    } // end of "if network!=null"

  }

  // sentenceGrammar4GeneralMethod

  public static void main(String[] args) throws IOException, NumberFormatException, SQLException {
    CALL_SentenceGrammar sg = new CALL_SentenceGrammar();
    // String targetSentence =
    // "���܂� �� �e�[�u�� �� ���� �� ����܂�����";//should modify the voca file
    // after generated
    // String targetSentence = "���ǂ� �� ������ �� �̂܂��܂���";
    // sg.sentenceGrammar4GeneralMethod(targetSentence,34,3);
    // MakeDFA dfa = new MakeDFA();
    // //dfa.getDFAFile(pathfile);
    // String name = new String("NO5");
    // dfa.getDFAFile(name);

    sg.sentenceGrammar4GeneralMethod("SpeechSentencesStageTwo");

    System.out.println("finished");
  }

}
